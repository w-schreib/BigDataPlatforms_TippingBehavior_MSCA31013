{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data - Group Project \n",
    "#### Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://md01.rcc.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0-cdh6.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fef915fc4a8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkBasics').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change configuration settings on Spark \n",
    "# change the value of the execute memory . Same as at work. \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'),\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'), \n",
    "                                        ('spark.executor.cores', '4'), \n",
    "                                        ('spark.cores.max', '4'), \n",
    "                                        ('spark.driver.memory','4g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.defaultParallelism\n",
    "sc._jsc.sc().getExecutorMemoryStatus().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "ls: `<hdfs location>': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Check data exists in location\n",
    "!hadoop fs -ls -d \"<hdfs location>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 ms, sys: 4.03 ms, total: 7.48 ms\n",
      "Wall time: 7.25 s\n",
      "+--------------------+----+-----------+-----+---+-------------+-------+\n",
      "|            LOCATION|YEAR|       TEAM|MONTH|DAY| NEIGHBORHOOD|nb_code|\n",
      "+--------------------+----+-----------+-----+---+-------------+-------+\n",
      "|Guaranteed Rate F...|2019|WHITE SOCKS|    3| 20|Armour Square|     34|\n",
      "|       Wrigley Field|2019|       CUBS|    3| 21|     Lakeview|      6|\n",
      "|       Wrigley Field|2019|       CUBS|    3| 21|     Lakeview|      6|\n",
      "|Guaranteed Rate F...|2019|WHITE SOCKS|    3| 21|Armour Square|     34|\n",
      "|       Wrigley Field|2019|       CUBS|    3| 22|     Lakeview|      6|\n",
      "+--------------------+----+-----------+-----+---+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the right way to read a file - from HDFS in this case\n",
    "%time df = spark.read.csv(\"/user/josefinabollini/GroupProject/games_CUBS_socks.csv\", inferSchema=True, header=True)\n",
    "import pyspark.sql.functions as f\n",
    "df = df.withColumn('MONTH_ok',f.col('DAY'))\n",
    "df = df.withColumn('DAY_ok',f.col('MONTH')).drop('MONTH','DAY')\n",
    "df =  df.withColumnRenamed('MONTH_ok','MONTH').withColumnRenamed('DAY_ok','DAY')\n",
    "df = df.withColumn('NEIGHBORHOOD',f.when(f.col('LOCATION') == 'Wrigley Field','Lakeview').otherwise('Armour Square'))\n",
    "df = df.withColumn('nb_code',f.when(f.col('LOCATION') == 'Wrigley Field',6).otherwise(34))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 ms, sys: 5.35 ms, total: 7.71 ms\n",
      "Wall time: 9.18 s\n",
      "+-------------+---+-----+----+--------------+----------+-------+\n",
      "|     LOCATION|DAY|MONTH|YEAR|  NEIGHBORHOOD|      TEAM|nb_code|\n",
      "+-------------+---+-----+----+--------------+----------+-------+\n",
      "|United Center| 11|   10|2019|NEAR WEST SIDE|BLACKHAWKS|     28|\n",
      "|United Center| 12|   10|2019|NEAR WEST SIDE|BLACKHAWKS|     28|\n",
      "|United Center| 15|   10|2019|NEAR WEST SIDE|BLACKHAWKS|     28|\n",
      "|United Center| 19|   10|2019|NEAR WEST SIDE|BLACKHAWKS|     28|\n",
      "|United Center| 20|   10|2019|NEAR WEST SIDE|BLACKHAWKS|     28|\n",
      "+-------------+---+-----+----+--------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time other_events_df = spark.read.csv(\"/user/josefinabollini/GroupProject/otherEvents.csv\", inferSchema=True, header=True)\n",
    "other_events_df =  other_events_df.withColumnRenamed('Location','LOCATION').withColumnRenamed('NEIGHBOURHOOD','NEIGHBORHOOD')\n",
    "other_events_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+------------------+--------------+-----------+-----------------+\n",
      "|summary|            LOCATION|               DAY|             MONTH|              YEAR|  NEIGHBORHOOD|       TEAM|          nb_code|\n",
      "+-------+--------------------+------------------+------------------+------------------+--------------+-----------+-----------------+\n",
      "|  count|                 582|               582|               582|               582|           582|        582|              582|\n",
      "|   mean|                null|15.895189003436426| 6.733676975945017|2020.0618556701031|          null|       null|22.72680412371134|\n",
      "| stddev|                null| 8.847591397903198|2.8855745232467673|0.9920277707270452|          null|       null|12.29804581650141|\n",
      "|    min|Guaranteed Rate F...|                 1|                 1|              2019| Armour Square|      BEARS|                6|\n",
      "|    max|       Wrigley Field|                31|                12|              2022|NEAR WEST SIDE|WHITE SOCKS|               34|\n",
      "+-------+--------------------+------------------+------------------+------------------+--------------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"LOCATION\",\"DAY\",\"MONTH\",\"YEAR\",\"NEIGHBORHOOD\",'TEAM','nb_code')\n",
    "other_events_df = other_events_df.select(\"LOCATION\",\"DAY\",\"MONTH\",\"YEAR\",\"NEIGHBORHOOD\",'TEAM','nb_code')\n",
    "\n",
    "df3 = df.unionAll(other_events_df)\n",
    "df3.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.toPandas().to_csv(\"/home/josefinabollini/GroupProject/All_events_aligned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data - Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 ms, sys: 4.76 ms, total: 7.52 ms\n",
      "Wall time: 8.17 s\n",
      "CPU times: user 4.22 ms, sys: 1.06 ms, total: 5.27 ms\n",
      "Wall time: 539 ms\n",
      "CPU times: user 6.02 ms, sys: 0 ns, total: 6.02 ms\n",
      "Wall time: 875 ms\n"
     ]
    }
   ],
   "source": [
    "%time df21 = spark.read.csv(\"/user/josefinabollini/GroupProject/2021weatherdata.csv\", inferSchema=True, header=True)\n",
    "%time df22 = spark.read.csv(\"/user/josefinabollini/GroupProject/2022weatherdata.csv\", inferSchema=True, header=True)\n",
    "%time df1920 = spark.read.csv(\"/user/josefinabollini/GroupProject/2019-2020weatherdata.csv\", inferSchema=True, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-31-9825d92d2840>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-9825d92d2840>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df1920.option(\"quote\", \"\"\").show(10)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "df1920.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
