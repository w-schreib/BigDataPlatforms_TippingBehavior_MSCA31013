{"cells":[{"cell_type":"markdown","id":"53477fb5","metadata":{},"source":["### Final Project\n","MScA 31013 Big Data Platforms\n","# Machine Learning Models: Predicting Tip Percent\n","\n","***Tip percent refers to the percent of ride cost (fare + additional charges) that a rider tips***"]},{"cell_type":"code","execution_count":12,"id":"6b20316f","metadata":{},"outputs":[],"source":["# import libraries\n","from pyspark.sql import SparkSession\n","from pyspark.sql import Row\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark.mllib.util import MLUtils\n","from pyspark.ml.feature import StandardScaler\n","from pyspark.ml import Pipeline\n","from pyspark.ml.feature import StringIndexer,IndexToString,VectorAssembler,OneHotEncoder\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.classification import GBTClassifier\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","import pyspark.ml.tuning as tune\n","from pyspark.ml.tuning import CrossValidatorModel\n","from pyspark.ml import PipelineModel\n","import pandas as pd\n","import numpy as np\n","\n","sc = spark.sparkContext\n","spark = SparkSession.builder.appName('BDP-GroupProject').getOrCreate()\n","\n","spark.conf.set(\"spark.sql.debug.maxToStringFields\", 50)"]},{"cell_type":"code","execution_count":13,"id":"8b4c88c8","metadata":{},"outputs":[],"source":["def read_data(path):\n","    table = spark.read \\\n","    .option(\"quote\", \"\\\"\")  \\\n","    .option(\"escape\", \"\\\"\") \\\n","    .option(\"ignoreLeadingWhiteSpace\",True) \\\n","    .option(\"multiline\", True)\\\n","    .csv(path,inferSchema=True, header=True )\n","    return table\n","\n","# read in modeling dataset\n","df0 = spark.read.parquet('gs://big-data-final/model-data/final-model-with-feature.parquet')\n","\n","# select subset of features\n","var_list = [\n"," 'tip_pct',\n"," 'fare_add',\n"," 'add_charge_pct',\n"," 'trip_seconds',\n"," 'trip_miles',\n"," 'trip_start_year',\n","#'trip_start_month',\n"," 'winter',\n"," 'spring',\n"," 'summer',\n"," 'trip_start_dow',\n"," 'ride_type',\n"," 'shared_trip_authorized',\n"," 'rain_snow',\n"," 'community_eventCnt',\n","#'pickup_community_name',\n","#'dropoff_community_name',\n"," 'outside_chicago_ride',\n"," 'covid_deaths_sma7'\n","]\n","model_df = df0.select(var_list)"]},{"cell_type":"markdown","id":"503afe73","metadata":{},"source":["# Data Engineering Cont."]},{"cell_type":"markdown","id":"58cd5162","metadata":{},"source":["## Feature Generation"]},{"cell_type":"code","execution_count":14,"id":"5855858f","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#-----\n","# Create StringIndexer to OneHotEncoder\n","#-----\n","# dow\n","dow_indexer = StringIndexer(inputCol='trip_start_dow', \n","                            outputCol='dow_idx')\n","dow_encoder = OneHotEncoder(inputCol='dow_idx',\n","                            outputCol='dow_vec')\n","# month\n","#month_indexer = StringIndexer(inputCol='trip_start_month', \n","#                              outputCol='month_idx')\n","#month_encoder = OneHotEncoder(inputCol='month_idx',\n","#                              outputCol='month_vec')\n","# pickup community area\n","#pickup_indexer = StringIndexer(inputCol='pickup_community_name', \n","#                               outputCol='pickup_idx')\n","#pickup_encoder = OneHotEncoder(inputCol='pickup_idx', \n","#                               outputCol='pickup_vec')\n","# dropoff community area\n","#dropoff_indexer = StringIndexer(inputCol='dropoff_community_name', \n","#                                outputCol='dropoff_idx')\n","#dropoff_encoder = OneHotEncoder(inputCol='dropoff_idx', \n","#                                outputCol='dropoff_vec')\n","\n","#-----\n","# Make a VectorAssembler\n","#-----\n","vectorAssembler = VectorAssembler(inputCols=['fare_add',\n","                                             'add_charge_pct',\n","                                             'trip_seconds',\n","                                             'trip_miles',\n","                                             'ride_type',\n","                                             'shared_trip_authorized',\n","                                             'rain_snow',\n","                                             'community_eventCnt',\n","                                             'outside_chicago_ride',\n","                                             'covid_deaths_sma7',\n","                                             'trip_start_year',\n","                                             'winter',\n","                                             'spring',\n","                                             'summer',\n","                                             'dow_vec'#,'month_vec',\n","                                             #'pickup_idx','pickup_vec',\n","                                             #'dropoff_idx','dropoff_vec'\n","                                            ],\n","                                  outputCol='features')\n","\n","#-----\n","# Standardize features\n","#-----\n","scaler = StandardScaler(inputCol=\"features\",   \n","                        outputCol=\"scaledFeatures\")\n","\n","#-----\n","# Make the pipeline\n","#-----\n","transit_pipe = Pipeline(stages=[dow_indexer,dow_encoder,\n","                                #month_indexer,month_encoder,\n","                                #pickup_indexer,pickup_encoder,\n","                                #dropoff_indexer,dropoff_encoder,\n","                                vectorAssembler,\n","                                scaler])\n","\n","#-----\n","# Fit and transform the training data\n","#-----\n","piped_df = transit_pipe.fit(model_df).transform(model_df)"]},{"cell_type":"markdown","id":"90231d97","metadata":{},"source":["**Day of Week**\n","\n","`trip_start_dow`\n","- 1 = Sunday\n","- 7 = Saturday\n","\n","`dow_idx` is reindexed by frequency"]},{"cell_type":"code","execution_count":15,"id":"63011825","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 35:=====================================================>  (46 + 2) / 48]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------+-------+-------------+\n","|trip_start_dow|dow_idx|      dow_vec|\n","+--------------+-------+-------------+\n","|             7|    0.0|(6,[0],[1.0])|\n","|             2|    6.0|    (6,[],[])|\n","|             6|    1.0|(6,[1],[1.0])|\n","|             5|    2.0|(6,[2],[1.0])|\n","|             3|    5.0|(6,[5],[1.0])|\n","|             1|    3.0|(6,[3],[1.0])|\n","|             4|    4.0|(6,[4],[1.0])|\n","+--------------+-------+-------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["piped_df.select('trip_start_dow','dow_idx','dow_vec').distinct().show()"]},{"cell_type":"markdown","id":"cc246c73","metadata":{},"source":["## Split data into training & test sets"]},{"cell_type":"code","execution_count":16,"id":"7e2238a1","metadata":{},"outputs":[],"source":["# Split the data into training and test sets.\n","training, test = piped_df.randomSplit([0.7, 0.3],0.0)"]},{"cell_type":"markdown","id":"5e86fdeb","metadata":{},"source":["# Random Forest Regressor"]},{"cell_type":"code","execution_count":17,"id":"8074f628","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml.evaluation import RegressionEvaluator"]},{"cell_type":"markdown","id":"8824f264","metadata":{},"source":["Train model"]},{"cell_type":"code","execution_count":null,"id":"b3d4097d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["rf = RandomForestRegressor(labelCol='tip_pct', featuresCol=\"features\")\n","rfm = rf.fit(training)"]},{"cell_type":"markdown","id":"6dbded1d","metadata":{},"source":["Performance on training data"]},{"cell_type":"code","execution_count":null,"id":"4cc8aa0a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 60:======================================================> (47 + 1) / 48]\r"]},{"name":"stdout","output_type":"stream","text":["training rmse:  0.7728764866929401\n","training R2:  0.003499787754531636\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#-----\n","# predictions on training data\n","#-----\n","trainPred = rfm.transform(training)\n","\n","#-----\n","# evaluate performance on training data\n","#-----\n","evaluator = RegressionEvaluator(labelCol=\"tip_pct\", \n","                                predictionCol=\"prediction\", \n","                                metricName=\"rmse\")\n","evaluator_r2 = RegressionEvaluator(labelCol=\"tip_pct\", \n","                                   predictionCol=\"prediction\",\n","                                   metricName=\"r2\")\n","rmseTrain = evaluator.evaluate(trainPred)                                                                               \n","r2Train = evaluator_r2.evaluate(trainPred)\n","\n","print(\"training rmse: \", rmseTrain)\n","print(\"training R2: \", r2Train)"]},{"cell_type":"markdown","id":"9e829639","metadata":{},"source":["Performance on test data"]},{"cell_type":"code","execution_count":null,"id":"ab608845","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 64:======================================================> (47 + 1) / 48]\r"]},{"name":"stdout","output_type":"stream","text":["test rmse:  0.8728565556790877\n","test R2:  0.002690292800045402\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#-----\n","# predictions on test data\n","#-----\n","testPred = rfm.transform(test)\n","\n","#-----\n","# evaluate performance on test data\n","#-----\n","evaluator = RegressionEvaluator(labelCol=\"tip_pct\", \n","                                predictionCol=\"prediction\", \n","                                metricName=\"rmse\")\n","evaluator_r2 = RegressionEvaluator(labelCol=\"tip_pct\", \n","                                   predictionCol=\"prediction\",\n","                                   metricName=\"r2\")\n","rmseTest = evaluator.evaluate(testPred)                                                                               \n","r2Test = evaluator_r2.evaluate(testPred)\n","\n","print(\"test rmse: \", rmseTest)\n","print(\"test R2: \", r2Test)"]},{"cell_type":"markdown","id":"89ba7259","metadata":{},"source":["Feature Importance"]},{"cell_type":"code","execution_count":20,"id":"6ad17f3a","metadata":{},"outputs":[{"data":{"text/plain":["SparseVector(20, {0: 0.1451, 1: 0.0932, 2: 0.0613, 3: 0.1574, 4: 0.3511, 5: 0.0623, 7: 0.0, 8: 0.0048, 9: 0.0158, 10: 0.0275, 11: 0.003, 12: 0.0045, 13: 0.0084, 14: 0.0012, 15: 0.0, 16: 0.0011, 17: 0.0008, 18: 0.0002, 19: 0.0624})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["rfm.featureImportances"]},{"cell_type":"markdown","id":"1b3eb3b4","metadata":{},"source":["# Save Trained Models"]},{"cell_type":"code","execution_count":null,"id":"4b1b32f4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#https://www.sparkitecture.io/machine-learning/model-saving-and-loading\n","rfm.save(\"/mnt/trainedmodels/rfm\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}